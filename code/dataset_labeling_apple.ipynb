{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bffa208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b35a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_destination(destination: str) -> int:\n",
    "    if destination == \"Broadcast\": \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def check_null_value(string_to_check: str) -> str:\n",
    "    if pd.isna(string_to_check):\n",
    "        return \"\"\n",
    "    else:\n",
    "        return string_to_check\n",
    "\n",
    "\n",
    "def assign_device(device: str, source: str) -> str:\n",
    "    return device\n",
    "\n",
    "\n",
    "def encode_company_id(company: str, source: str, service_data: str) -> str:\n",
    "    # Defined, but not named company identifiers f.e. 0x34f5\n",
    "    if str(company).startswith(\"0x\") and len(company) == 6:\n",
    "        return \"Unknown\"\n",
    "    elif pd.isna(company):\n",
    "        return \"Undefined\"\n",
    "    else:\n",
    "        return company\n",
    "\n",
    "\n",
    "def extract_time(delta_string: str) -> int:\n",
    "    if pd.isna(delta_string):\n",
    "        return 0\n",
    "    else:\n",
    "        return int(delta_string.replace(\"\\\\302\\\\265s\", \"\"))\n",
    "\n",
    "\n",
    "def check_company_id_existence(company_id: str) -> int:\n",
    "    if company_id == \"Undefined\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def extract_length(entry_to_exctract: str) -> int:\n",
    "    if pd.isna(entry_to_exctract):\n",
    "        return 0\n",
    "    else:\n",
    "        return len(entry_to_exctract)\n",
    "\n",
    "\n",
    "def is_adv_channel(channel: int) -> bool:\n",
    "    if channel in [37, 38, 39]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def check_entry_existence(entry_to_check: str) -> int:\n",
    "    if pd.isna(entry_to_check):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fbde1b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the input CSV file and rename some columns\n",
    "def read_data_to_df(file_name: str) -> pd.DataFrame:\n",
    "    dataset_df = pd.read_csv(file_name, encoding='ISO-8859-1', low_memory=False)\n",
    "    a = dataset_df.columns\n",
    "    dataset_df.columns = dataset_df.columns.str.replace(\"Packet time (start to end)\", \"packet_start_end\")\n",
    "    dataset_df.columns = dataset_df.columns.str.replace(\"Delta time (end to start)\", \"delta_end_start\")\n",
    "    dataset_df.columns = dataset_df.columns.str.replace(\"Delta time (start to start)\", \"delta_start_start\")\n",
    "    dataset_df.columns = dataset_df.columns.str.replace(\" \", \"_\")\n",
    "    dataset_df.columns = dataset_df.columns.str.replace(\"Test\", \"Device\")\n",
    "    return dataset_df\n",
    "\n",
    "def initialize_source_dictionaries(all_unique_sources: list) -> None:\n",
    "    for source in all_unique_sources:\n",
    "        if str(source) != \"nan\":\n",
    "            source_dictionaries[source] = {}\n",
    "            source_dictionaries[source][\"count\"] = 0\n",
    "            source_dictionaries[source][\"malformed_count\"] = 0\n",
    "            source_dictionaries[source][\"highest_rssi\"] = 0\n",
    "            source_dictionaries[source][\"lowest_rssi\"] = -100\n",
    "            source_dictionaries[source][\"average_rssi\"] = 0 # CHANGED: added average rssi for improved filtering\n",
    "            source_dictionaries[source][\"first_occurence\"] = -1\n",
    "            source_dictionaries[source][\"last_occurence\"] = 0\n",
    "            source_dictionaries[source][\"device\"] = \"empty\"\n",
    "            source_dictionaries[source][\"sub_device\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dcaf9b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign values for each row with either simple transformations or direct value usage\n",
    "def fill_labelled_columns(packet_data: tuple, device: str, sub_device: str):\n",
    "\n",
    "    row_data = {\n",
    "        \"time\": packet_data.Time,\n",
    "        \"source\": packet_data.Source,\n",
    "        \"destination\": packet_data.Destination,\n",
    "        \"is_broadcast\": assign_destination(packet_data.Destination),\n",
    "        \"length\": packet_data.Length,\n",
    "        \"info\": packet_data.Info,\n",
    "        \"rssi\": packet_data.RSSI,\n",
    "        \"company_id\": encode_company_id(packet_data.Company_ID, packet_data.Source, packet_data.Service_Data),\n",
    "        \"has_company_id\": check_company_id_existence(encode_company_id(packet_data.Company_ID, packet_data.Source, packet_data.Service_Data)),\n",
    "        \"channel\": packet_data.Channel_Index,\n",
    "        \"is_adv_channel\": is_adv_channel(packet_data.Channel_Index),\n",
    "        \"device_name\": check_null_value(packet_data.Device_Name),\n",
    "        \"uuid16\": check_null_value(packet_data.UUID_16),\n",
    "        \"has_uuid16\": check_entry_existence(packet_data.UUID_16),\n",
    "        \"len_uuid16\": extract_length(packet_data.UUID_16),\n",
    "        \"uuid128\": check_null_value(packet_data.UUID128),\n",
    "        \"has_uuid128\": check_entry_existence(packet_data.UUID128),\n",
    "        \"data\": check_null_value(packet_data.Data),\n",
    "        \"len_data\": extract_length(packet_data.Data),\n",
    "        \"ad_type\": check_null_value(packet_data.Type),\n",
    "        \"len_ad_type\": extract_length(packet_data.Data),\n",
    "        \"service_data\": check_null_value(packet_data.Service_Data),\n",
    "        \"len_service_data\": extract_length(packet_data.Service_Data),\n",
    "        \"crc\": check_null_value(packet_data.CRC),\n",
    "        \"labelled_device\": assign_device(device, packet_data.Source),\n",
    "        \"sublabel_device\": sub_device,\n",
    "        \"time_start_end\": extract_time(packet_data.packet_start_end),\n",
    "        \"delta_end_start\": extract_time(packet_data.delta_end_start),\n",
    "        \"delta_start_start\": extract_time(packet_data.delta_start_start)\n",
    "    }\n",
    "\n",
    "    # To ensure labeling quality, phone-based labels which do not a valid company_id are labeled empty\n",
    "    # Valid company_ids include: [\"Samsung Electronics Co. Ltd.\", \"Undefined\", \"Unknown\"]\n",
    "    # Invalid company_ids include: Any other company such as \"Apple\", \"Conneqtech B.V.\" etc.\n",
    "    if row_data[\"labelled_device\"] in ['iPad', 'AirPods', 'AirTag'] and row_data[\"company_id\"] not in companies:\n",
    "        row_data[\"labelled_device\"] = \"empty\"\n",
    "        row_data[\"sublabel_device\"] = \"empty\"\n",
    "\n",
    "    return row_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2f2d93cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main raw dataset input parsing method\n",
    "def parse_dataframe(input_dataframe: pd.DataFrame):\n",
    "    # Define some helper variables for tracking of outliers\n",
    "    nan_discarded_counter = 0\n",
    "    malformed_discarded_counter = 0\n",
    "    airtag_list = []\n",
    "    airpods_list = []\n",
    "    ipad_list = []\n",
    "\n",
    "    dict_mean_rssi = (\n",
    "        pd.to_numeric(\n",
    "            input_dataframe[\"RSSI\"].astype(str).str.replace(\"dBm\", \"\", regex=False).str.strip(),\n",
    "            errors=\"coerce\"\n",
    "        )\n",
    "        .groupby(input_dataframe[\"Source\"])\n",
    "        .mean()\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    for row in input_dataframe.itertuples(index=False):\n",
    "        # Skip the source \"nan\" and keep track of packets\n",
    "        if str(row.Source) == \"nan\":\n",
    "            nan_discarded_counter += 1\n",
    "            continue\n",
    "\n",
    "        # Any source != \"nan\" is valid, therefore we can increase the counter of source packets here\n",
    "        source_dictionaries[row.Source][\"count\"] += 1\n",
    "\n",
    "        # Skip malformed packets and keep track of occurrences\n",
    "        if \"Malformed Packet\" in row.Info:\n",
    "            source_dictionaries[row.Source][\"malformed_count\"] += 1\n",
    "            malformed_discarded_counter += 1\n",
    "            continue\n",
    "\n",
    "        current_rssi = row.RSSI\n",
    "\n",
    "        # Assign and overwrite source dictionary values with the current row\n",
    "        if source_dictionaries[row.Source][\"first_occurence\"] == -1:\n",
    "            source_dictionaries[row.Source][\"first_occurence\"] = row.Time\n",
    "        if row.Time > source_dictionaries[row.Source][\"last_occurence\"]:\n",
    "            source_dictionaries[row.Source][\"last_occurence\"] = row.Time\n",
    "        if current_rssi > source_dictionaries[row.Source][\"lowest_rssi\"]:\n",
    "            source_dictionaries[row.Source][\"lowest_rssi\"] = current_rssi\n",
    "        if current_rssi < source_dictionaries[row.Source][\"highest_rssi\"]:\n",
    "            source_dictionaries[row.Source][\"highest_rssi\"] = current_rssi\n",
    "        # CHANGED: inserted average rssi\n",
    "        if source_dictionaries[row.Source][\"average_rssi\"] == 0:\n",
    "            source_dictionaries[row.Source][\"average_rssi\"] = dict_mean_rssi[row.Source]\n",
    "\n",
    "        # Label conditions for the AirPods\n",
    "        if row.Company_ID in companies and row.Info == \"ADV_SCAN_IND\" and row.Length == 63:\n",
    "            airpods_list.append(row.Source)\n",
    "            source_dictionaries[row.Source][\"device\"] = \"AirPods\"\n",
    "            source_dictionaries[row.Source][\"sub_device\"] = \"AirPods\"\n",
    "\n",
    "        # Label conditions for the AirTag\n",
    "        if row.Company_ID in companies and row.Info == \"ADV_IND\" and (row.Length == 63 or row.Length == 40):\n",
    "            airtag_list.append(row.Source)\n",
    "            source_dictionaries[row.Source][\"device\"] = \"AirTag\"\n",
    "            source_dictionaries[row.Source][\"sub_device\"] = \"AirTag\"\n",
    "        \n",
    "        # Label conditions for the iPad\n",
    "        if row.Company_ID in companies and row.Info == \"ADV_IND\" and (row.Length == 50 or row.Length == 49):\n",
    "            source_dictionaries[row.Source][\"device\"] = \"iPad\"\n",
    "            source_dictionaries[row.Source][\"sub_device\"] = \"iPad\"\n",
    "\n",
    "        # After assigning all values, create a transformed row for the final list of rows\n",
    "        row_data = fill_labelled_columns(row, source_dictionaries[row.Source][\"device\"], source_dictionaries[row.Source][\"sub_device\"])\n",
    "        final_list.append(row_data)\n",
    "\n",
    "    return nan_discarded_counter, malformed_discarded_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5cd47ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_empty_and_malformed_sources():\n",
    "    only_malformed_sources = []\n",
    "    empty_sources = []\n",
    "\n",
    "    for key in source_dictionaries.keys():\n",
    "        count = source_dictionaries[key][\"count\"]\n",
    "        malformed_count = source_dictionaries[key][\"malformed_count\"]\n",
    "        device = source_dictionaries[key][\"device\"]\n",
    "\n",
    "        # If there are only malformed packets, a source is \"malformed-only\"\n",
    "        if (count - malformed_count) == 0:\n",
    "            only_malformed_sources.append(key)\n",
    "        \n",
    "        # Get all sources which are not part of the target group (and contain at least 1 valid packet)\n",
    "        if (count - malformed_count) != 0 and device == \"empty\":\n",
    "            empty_sources.append(key)\n",
    "\n",
    "    print(f\"Only Malformed Sources: {len(only_malformed_sources)}\")\n",
    "    print(f\"Empty Sources: {len(empty_sources)}\")\n",
    "\n",
    "    return only_malformed_sources, empty_sources\n",
    "\n",
    "# Recursively reassign sources due to non-deterministic BLE packet contents\n",
    "# --> Extensively described in the thesis\n",
    "def reassign_sources():\n",
    "    empty_occurrences = 0\n",
    "    new_final_list = []\n",
    "\n",
    "    for row_dict in final_list:\n",
    "        if row_dict[\"labelled_device\"] == \"empty\" and row_dict[\"company_id\"] in companies:\n",
    "            current_source = row_dict[\"source\"]\n",
    "            row_dict[\"labelled_device\"] = source_dictionaries[current_source][\"device\"]\n",
    "\n",
    "        if row_dict[\"labelled_device\"] != \"empty\":\n",
    "            new_final_list.append(row_dict)\n",
    "        else:\n",
    "            new_final_list.append(row_dict)\n",
    "            empty_occurrences += 1\n",
    "\n",
    "    return empty_occurrences, new_final_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0d4afde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final dataframe based on the final_list rows\n",
    "def create_labelled_dataframe(entry_list: list):\n",
    "    new_df = pd.DataFrame(data=entry_list, columns=list((final_list[0].keys())))        \n",
    "    return new_df\n",
    "\n",
    "# Write the dataframe to a file\n",
    "def write_new_dataframe(file_to_write: str, df_to_write: pd.DataFrame):\n",
    "    df_to_write.to_csv(file_to_write, encoding='utf-8', index=False)\n",
    "    print(f\"New CSV written as: {file_to_write}\")\n",
    "\n",
    "# Extract information about the sources of a label\n",
    "def info_extractor(df_input: pd.DataFrame, wanted_label: str):\n",
    "    seen_sources = {}\n",
    "    for row in df_input.itertuples(index=False):\n",
    "        if row.source not in seen_sources.keys() and row.sublabel_device == wanted_label:\n",
    "            seen_sources[row.source] = {}\n",
    "            seen_sources[row.source][\"first\"] = row.time\n",
    "            seen_sources[row.source][\"last\"] = row.time\n",
    "            seen_sources[row.source][\"count\"] = source_dictionaries[row.source][\"count\"]\n",
    "            continue\n",
    "        if row.source in seen_sources.keys() and row.sublabel_device == wanted_label:\n",
    "            if seen_sources[row.source][\"last\"] < row.time:\n",
    "                seen_sources[row.source][\"last\"] = row.time\n",
    "\n",
    "    return seen_sources\n",
    "\n",
    "def assign_majority_label(input_df: pd.DataFrame):\n",
    "    # Compute the majority label per source\n",
    "    majority_labels = input_df.groupby('source')['labelled_device'].agg(lambda x: x.mode()[0])\n",
    "    # Map the majority label back to the dataframe\n",
    "    input_df['labelled_device'] = input_df['source'].map(majority_labels)\n",
    "    input_df['sublabel_device'] = input_df['source'].map(majority_labels)\n",
    "\n",
    "    return input_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1aa84950",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#        CODE FIELD 0        #\n",
    "##############################\n",
    "\n",
    "# Global variables\n",
    "final_list = []\n",
    "source_dictionaries = {}\n",
    "companies = [\"Apple, Inc.\"]\n",
    "undefined_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4114b931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only Malformed Sources: 106828\n",
      "Empty Sources: 86496\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "#        CODE FIELD 1        #\n",
    "##############################\n",
    "\n",
    "# Setup all lists, dictionaries and the labeled dataframe\n",
    "path_to_file = \"../data/apple/apple_uni_group1_2h_raw.csv\" # apple_isolated_group1_6h_raw, apple_apartment_group1_6h_1_raw, apple_apartment_group1_6h_2_raw, apple_apartment_group1_6h_3_raw, apple_uni_group1_2h_raw\n",
    "raw_dataframe = read_data_to_df(path_to_file)\n",
    "all_sources = raw_dataframe[\"Source\"].unique()\n",
    "initialize_source_dictionaries(all_sources)\n",
    "nan_counter, malformed_counter = parse_dataframe(raw_dataframe)\n",
    "malformed_list, empty_list = find_empty_and_malformed_sources()\n",
    "empty_counter, filtered_list = reassign_sources()\n",
    "labelled_dataframe = create_labelled_dataframe(filtered_list)\n",
    "relevant_sources = labelled_dataframe[\"source\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0451d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "FINAL DATAFRAME\n",
      "\n",
      "Length Raw Dataframe: 2769929\n",
      "Length Final Dataframe: 2530814\n",
      "Removed: 226623 (malformed), 12492 (NaN), Diff: 239115\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "#        CODE FIELD 2        #\n",
    "##############################\n",
    "\n",
    "# For all target group devices, labeling needs to be closely inspected and adjusted\n",
    "# Therefore, each source is filtered according to some criteria and re-labeled if needed\n",
    "\n",
    "rssi_limits_per_dataset =  {\"apple_isolated_group1_6h_raw\": {\"iPad\": -41,\n",
    "                                                        \"AirTag\": -64,\n",
    "                                                        \"AirPods\": -45},\n",
    "                            \"apple_apartment_group1_6h_1_raw\": {\"iPad\": -49,\n",
    "                                                        \"AirTag\": -48,\n",
    "                                                        \"AirPods\": -31},\n",
    "                            \"apple_apartment_group1_6h_2_raw\": {\"iPad\": -42,\n",
    "                                                        \"AirTag\": -31,\n",
    "                                                        \"AirPods\": -22},\n",
    "                            \"apple_apartment_group1_6h_3_raw\": {\"iPad\": -43,\n",
    "                                                        \"AirTag\": -25,\n",
    "                                                        \"AirPods\": -21},\n",
    "                            \"apple_uni_group1_2h_raw\": {\"iPad\": -24,\n",
    "                                                        \"AirTag\": -34,\n",
    "                                                        \"AirPods\": -17},\n",
    "                            }\n",
    "\n",
    "dataset = path_to_file.split(\"/\")[-1].split(\".\")[0]\n",
    "rssi_limits = rssi_limits_per_dataset[dataset]\n",
    "\n",
    "for label in rssi_limits.keys():\n",
    "    sources = info_extractor(labelled_dataframe, label)\n",
    "    actual_target_group_sources = []\n",
    "    for source in sources.keys():\n",
    "        first = round(sources[source][\"first\"], 3)\n",
    "        last = round(sources[source][\"last\"], 3)\n",
    "        count = sources[source][\"count\"]\n",
    "        avg_rssi = source_dictionaries[source][\"average_rssi\"]\n",
    "\n",
    "        # Find iPad labeled sources\n",
    "        if label == \"iPad\" and source_dictionaries[source][\"sub_device\"] == label:\n",
    "            if count > 30 and avg_rssi > rssi_limits[\"iPad\"]:\n",
    "                actual_target_group_sources.append(source)\n",
    "\n",
    "        # Find AirTag labeled sources\n",
    "        if label == \"AirTag\" and source_dictionaries[source][\"sub_device\"] == label:\n",
    "            if count > 30 and avg_rssi > rssi_limits[\"AirTag\"]:\n",
    "                actual_target_group_sources.append(source)\n",
    "\n",
    "        # Find AirPods labeled sources\n",
    "        if label == \"AirPods\" and source_dictionaries[source][\"sub_device\"] == label:\n",
    "            if count > 30 and avg_rssi > rssi_limits[\"AirPods\"]:\n",
    "                actual_target_group_sources.append(source)\n",
    "\n",
    "\n",
    "    # Reassign the labels based on the above conditions\n",
    "    current_target_group_sources = labelled_dataframe[labelled_dataframe['labelled_device'] == label][\"source\"]\n",
    "    diff_sources = set(current_target_group_sources) - set(actual_target_group_sources)\n",
    "    labelled_dataframe.loc[labelled_dataframe['source'].isin(diff_sources), 'labelled_device'] = 'empty'\n",
    "    for scr in diff_sources:\n",
    "        source_dictionaries[scr][\"device\"] = \"empty\"\n",
    "        source_dictionaries[scr][\"sub_device\"] = \"empty\"\n",
    "\n",
    "\n",
    "# Print information about dataframe length\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"FINAL DATAFRAME\\n\")\n",
    "print(f\"Length Raw Dataframe: {len(raw_dataframe)}\")\n",
    "print(f\"Length Final Dataframe: {len(labelled_dataframe)}\")\n",
    "print(f\"Removed: {malformed_counter} (malformed), {nan_counter} (NaN), Diff: {len(raw_dataframe)-len(labelled_dataframe)}\")\n",
    "\n",
    "# Assign the majority label to impure sources\n",
    "labelled_dataframe = assign_majority_label(labelled_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "605b7996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  packets  sources\n",
      "labelled_device                  \n",
      "empty            2406592   106765\n",
      "AirPods            67983        9\n",
      "iPad               49208       10\n",
      "AirTag              7031        6\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "#        CODE FIELD 3        #\n",
    "##############################\n",
    "\n",
    "print(\"\\n\", labelled_dataframe.groupby(\"labelled_device\").agg(packets=(\"labelled_device\", \"size\"), sources=(\"source\", \"nunique\")).sort_values(by=\"packets\", ascending=False))\n",
    "# Check if there are still impure sources which have multiple labels\n",
    "# After assigning the majority label this output should be empty\n",
    "multi_label_sources = labelled_dataframe.groupby('source')['labelled_device'].nunique()\n",
    "multi_label_sources = multi_label_sources[multi_label_sources > 1].index\n",
    "\n",
    "for source in multi_label_sources:\n",
    "    print(\"There are source with multiple labels:\")\n",
    "    print(\"\\n\", labelled_dataframe[labelled_dataframe[\"source\"] == source][\"labelled_device\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbca9259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_src(df):\n",
    "    result = (\n",
    "    df.groupby(\"source\")\n",
    "      .agg(\n",
    "          count=(\"rssi\", \"count\"),\n",
    "          RSSI_min=(\"rssi\", \"min\"),\n",
    "          RSSI_max=(\"rssi\", \"max\"),\n",
    "          RSSI_avg=(\"rssi\", \"mean\"),\n",
    "          length_counts=(\"length\", lambda x: x.value_counts().to_dict()),\n",
    "          label=(\"labelled_device\", lambda x: x.unique())\n",
    "      )\n",
    "      .reset_index()                \n",
    "      .sort_values(by=\"count\", ascending=False)\n",
    "      .reset_index(drop=True)\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fc4a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#        CODE FIELD 4        #\n",
    "##############################\n",
    "\n",
    "# remove noise entries from isolated dataset\n",
    "if path_to_file.split(\"/\")[-1].split(\".\")[0].split(\"_\")[1] == \"isolated\":\n",
    "    print(group_by_src(labelled_dataframe[labelled_dataframe[\"labelled_device\"] == \"empty\"]).to_string())\n",
    "    # remove rows with empty device label\n",
    "    to_drop = (labelled_dataframe[\"labelled_device\"] == \"empty\")\n",
    "    labelled_dataframe = labelled_dataframe.drop(labelled_dataframe[to_drop].index)\n",
    "    print(f\"Number of entries with label 'empty': {len(labelled_dataframe[labelled_dataframe[\"labelled_device\"] == \"empty\"])}\")\n",
    "\n",
    "# save labelled dataframe as csv\n",
    "new_file_name = \"_\".join(path_to_file.split(\"/\")[-1].split(\".\")[0].split(\"_\")[:-1])\n",
    "labelled_dataframe.to_csv(f\"D../data/apple/{new_file_name}_labeled.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
