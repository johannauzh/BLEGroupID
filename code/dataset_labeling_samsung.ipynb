{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0bffa208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b35a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_destination(destination: str) -> int:\n",
    "    if destination == \"Broadcast\": \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def check_null_value(string_to_check: str) -> str:\n",
    "    if pd.isna(string_to_check):\n",
    "        return \"\"\n",
    "    else:\n",
    "        return string_to_check\n",
    "\n",
    "\n",
    "def assign_device(device: str, source: str) -> str:\n",
    "    if device in [\"Phone\", \"Phone Scan\", \"Phone Google\"]:\n",
    "        return \"Phone\"\n",
    "    else:\n",
    "        return device\n",
    "\n",
    "\n",
    "def encode_company_id(company: str, source: str, service_data: str) -> str:\n",
    "    # Defined, but not named company identifiers f.e. 0x34f5\n",
    "    if str(company).startswith(\"0x\") and len(company) == 6:\n",
    "        return \"Unknown\"\n",
    "    # Assign the Galaxy S22 \"Anonymous\" source the company Samsung\n",
    "    elif pd.isna(company) and source == \"Anonymous\":\n",
    "        return \"Samsung Electronics Co. Ltd.\"\n",
    "    # Reason?\n",
    "    elif pd.isna(company) and str(service_data).startswith(\"4a17235\"):\n",
    "        return \"Samsung Electronics Co. Ltd.\"\n",
    "    elif pd.isna(company):\n",
    "        return \"Undefined\"\n",
    "    else:\n",
    "        return company\n",
    "\n",
    "\n",
    "def extract_time(delta_string: str) -> int:\n",
    "    if pd.isna(delta_string):\n",
    "        return 0\n",
    "    else:\n",
    "        return int(delta_string.replace(\"\\\\302\\\\265s\", \"\"))\n",
    "\n",
    "\n",
    "def check_company_id_existence(company_id: str) -> int:\n",
    "    if company_id == \"Undefined\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def extract_length(entry_to_exctract: str) -> int:\n",
    "    if pd.isna(entry_to_exctract):\n",
    "        return 0\n",
    "    else:\n",
    "        return len(entry_to_exctract)\n",
    "\n",
    "\n",
    "def is_adv_channel(channel: int) -> bool:\n",
    "    if channel in [37, 38, 39]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def check_entry_existence(entry_to_check: str) -> int:\n",
    "    if pd.isna(entry_to_check):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fbde1b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the input CSV file and rename some columns\n",
    "def read_data_to_df(file_name: str) -> pd.DataFrame:\n",
    "    dataset_df = pd.read_csv(file_name, encoding='ISO-8859-1', low_memory=False)\n",
    "    a = dataset_df.columns\n",
    "    dataset_df.columns = dataset_df.columns.str.replace(\"Packet time (start to end)\", \"packet_start_end\")\n",
    "    dataset_df.columns = dataset_df.columns.str.replace(\"Delta time (end to start)\", \"delta_end_start\")\n",
    "    dataset_df.columns = dataset_df.columns.str.replace(\"Delta time (start to start)\", \"delta_start_start\")\n",
    "    dataset_df.columns = dataset_df.columns.str.replace(\" \", \"_\")\n",
    "    dataset_df.columns = dataset_df.columns.str.replace(\"Test\", \"Device\")\n",
    "    return dataset_df\n",
    "\n",
    "def initialize_source_dictionaries(all_unique_sources: list) -> None:\n",
    "    for source in all_unique_sources:\n",
    "        if str(source) != \"nan\":\n",
    "            source_dictionaries[source] = {}\n",
    "            source_dictionaries[source][\"count\"] = 0\n",
    "            source_dictionaries[source][\"malformed_count\"] = 0\n",
    "            source_dictionaries[source][\"highest_rssi\"] = 0\n",
    "            source_dictionaries[source][\"lowest_rssi\"] = -100\n",
    "            # CHANGED: added average rssi for improved filtering\n",
    "            source_dictionaries[source][\"average_rssi\"] = 0\n",
    "            source_dictionaries[source][\"first_occurence\"] = -1\n",
    "            source_dictionaries[source][\"last_occurence\"] = 0\n",
    "            source_dictionaries[source][\"device\"] = \"empty\"\n",
    "            source_dictionaries[source][\"sub_device\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dcaf9b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign values for each row with either simple transformations or direct value usage\n",
    "def fill_labelled_columns(packet_data: tuple, device: str, sub_device: str):\n",
    "\n",
    "    row_data = {\n",
    "        \"time\": packet_data.Time,\n",
    "        \"source\": packet_data.Source,\n",
    "        \"destination\": packet_data.Destination,\n",
    "        \"is_broadcast\": assign_destination(packet_data.Destination),\n",
    "        \"length\": packet_data.Length,\n",
    "        \"info\": packet_data.Info,\n",
    "        \"rssi\": packet_data.RSSI,\n",
    "        \"company_id\": encode_company_id(packet_data.Company_ID, packet_data.Source, packet_data.Service_Data),\n",
    "        \"has_company_id\": check_company_id_existence(encode_company_id(packet_data.Company_ID, packet_data.Source, packet_data.Service_Data)),\n",
    "        \"channel\": packet_data.Channel_Index,\n",
    "        \"is_adv_channel\": is_adv_channel(packet_data.Channel_Index),\n",
    "        \"device_name\": check_null_value(packet_data.Device_Name),\n",
    "        \"uuid16\": check_null_value(packet_data.UUID_16),\n",
    "        \"has_uuid16\": check_entry_existence(packet_data.UUID_16),\n",
    "        \"len_uuid16\": extract_length(packet_data.UUID_16),\n",
    "        \"uuid128\": check_null_value(packet_data.UUID128),\n",
    "        \"has_uuid128\": check_entry_existence(packet_data.UUID128),\n",
    "        \"data\": check_null_value(packet_data.Data),\n",
    "        \"len_data\": extract_length(packet_data.Data),\n",
    "        \"ad_type\": check_null_value(packet_data.Type),\n",
    "        \"len_ad_type\": extract_length(packet_data.Data),\n",
    "        \"service_data\": check_null_value(packet_data.Service_Data),\n",
    "        \"len_service_data\": extract_length(packet_data.Service_Data),\n",
    "        \"crc\": check_null_value(packet_data.CRC),\n",
    "        \"labelled_device\": assign_device(device, packet_data.Source),\n",
    "        \"sublabel_device\": sub_device,\n",
    "        \"time_start_end\": extract_time(packet_data.packet_start_end),\n",
    "        \"delta_end_start\": extract_time(packet_data.delta_end_start),\n",
    "        \"delta_start_start\": extract_time(packet_data.delta_start_start)\n",
    "    }\n",
    "\n",
    "    # To ensure labeling quality, phone-based labels which do not a valid company_id are labeled empty\n",
    "    # Valid company_ids include: [\"Samsung Electronics Co. Ltd.\", \"Undefined\", \"Unknown\"]\n",
    "    # Invalid company_ids include: Any other company such as \"Apple\", \"Conneqtech B.V.\" etc.\n",
    "    if row_data[\"labelled_device\"] in ['Phone'] and row_data[\"company_id\"] not in phone_companies:\n",
    "        row_data[\"labelled_device\"] = \"empty\"\n",
    "        row_data[\"sublabel_device\"] = \"empty\"\n",
    "\n",
    "    return row_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2f2d93cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main raw dataset input parsing method\n",
    "def parse_dataframe(input_dataframe: pd.DataFrame):\n",
    "    # Define some helper variables for tracking of outliers\n",
    "    nan_discarded_counter = 0\n",
    "    malformed_discarded_counter = 0\n",
    "    smart_tag_list = []\n",
    "    phone_list = []\n",
    "    buds_list = []\n",
    "\n",
    "    dict_mean_rssi = (\n",
    "        pd.to_numeric(\n",
    "            input_dataframe[\"RSSI\"].astype(str).str.replace(\"dBm\", \"\", regex=False).str.strip(),\n",
    "            errors=\"coerce\"\n",
    "        )\n",
    "        .groupby(input_dataframe[\"Source\"])\n",
    "        .mean()\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    for row in input_dataframe.itertuples(index=False):\n",
    "        # Skip the source \"nan\" and keep track of packets\n",
    "        if str(row.Source) == \"nan\":\n",
    "            nan_discarded_counter += 1\n",
    "            continue\n",
    "\n",
    "        # Any source != \"nan\" is valid, therefore we can increase the counter of source packets here\n",
    "        source_dictionaries[row.Source][\"count\"] += 1\n",
    "\n",
    "        # Skip malformed packets and keep track of occurrences\n",
    "        if \"Malformed Packet\" in row.Info:\n",
    "            source_dictionaries[row.Source][\"malformed_count\"] += 1\n",
    "            malformed_discarded_counter += 1\n",
    "            continue\n",
    "\n",
    "        current_rssi = row.RSSI\n",
    "\n",
    "        # Assign and overwrite source dictionary values with the current row\n",
    "        if source_dictionaries[row.Source][\"first_occurence\"] == -1:\n",
    "            source_dictionaries[row.Source][\"first_occurence\"] = row.Time\n",
    "        if row.Time > source_dictionaries[row.Source][\"last_occurence\"]:\n",
    "            source_dictionaries[row.Source][\"last_occurence\"] = row.Time\n",
    "        if current_rssi > source_dictionaries[row.Source][\"lowest_rssi\"]:\n",
    "            source_dictionaries[row.Source][\"lowest_rssi\"] = current_rssi\n",
    "        if current_rssi < source_dictionaries[row.Source][\"highest_rssi\"]:\n",
    "            source_dictionaries[row.Source][\"highest_rssi\"] = current_rssi\n",
    "        # CHANGED: inserted average rssi\n",
    "        if source_dictionaries[row.Source][\"average_rssi\"] == 0:\n",
    "            source_dictionaries[row.Source][\"average_rssi\"] = dict_mean_rssi[row.Source]\n",
    "            \n",
    "        # Label conditions for the smart tag\n",
    "        if row.Device_Name == \"Smart Tag\":\n",
    "            smart_tag_list.append(row.Source)\n",
    "            source_dictionaries[row.Source][\"device\"] = \"Smart Tag\"\n",
    "            source_dictionaries[row.Source][\"sub_device\"] = \"Smart Tag\"\n",
    "        if row.UUID_16 == \"Samsung Electronics Co., Ltd.,Samsung Electronics Co., Ltd.\":\n",
    "            smart_tag_list.append(row.Source)\n",
    "            source_dictionaries[row.Source][\"device\"] = \"Smart Tag\"\n",
    "            source_dictionaries[row.Source][\"sub_device\"] = \"Smart Tag\"\n",
    "\n",
    "        \n",
    "        # Label conditions for the phone\n",
    "        if row.UUID_16 == \"Google LLC\" and (row.Length == 63 or row.Length == 42 or row.Length == 120): \n",
    "            phone_list.append(row.Source)\n",
    "            source_dictionaries[row.Source][\"device\"] = \"Phone\"\n",
    "            source_dictionaries[row.Source][\"sub_device\"] = \"Phone Google\"\n",
    "        if row.Info == \"ADV_EXT_IND\" and row.Length == 39:\n",
    "            phone_list.append(row.Source)\n",
    "            source_dictionaries[row.Source][\"device\"] = \"Phone\"\n",
    "            source_dictionaries[row.Source][\"sub_device\"] = \"Phone Phone\"\n",
    "        if row.UUID_16 == \"Samsung Electronics Co. Ltd.\" and row.Length == 57: \n",
    "            phone_list.append(row.Source)\n",
    "            source_dictionaries[row.Source][\"device\"] = \"Phone\"\n",
    "            source_dictionaries[row.Source][\"sub_device\"] = \"Phone Phone\"\n",
    "        if row.Info == \"SCAN_REQ\" and row.Length == 38 and row.Destination in target_group_rsp_scrs:\n",
    "            phone_list.append(row.Source)\n",
    "            source_dictionaries[row.Source][\"device\"] = \"Phone\"\n",
    "            source_dictionaries[row.Source][\"sub_device\"] = \"Phone Scan\"\n",
    "\n",
    "        \n",
    "        # Label conditions for the buds\n",
    "        if row.Source == \"dc:b9:92:eb:f6:5d\":\n",
    "            source_dictionaries[row.Source][\"device\"] = \"Buds\"\n",
    "            source_dictionaries[row.Source][\"sub_device\"] = \"Buds\"\n",
    "\n",
    "        # After assigning all values, create a transformed row for the final list of rows\n",
    "        row_data = fill_labelled_columns(row, source_dictionaries[row.Source][\"device\"], source_dictionaries[row.Source][\"sub_device\"])\n",
    "        final_list.append(row_data)\n",
    "\n",
    "    return nan_discarded_counter, malformed_discarded_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5cd47ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_empty_and_malformed_sources():\n",
    "    only_malformed_sources = []\n",
    "    empty_sources = []\n",
    "\n",
    "    for key in source_dictionaries.keys():\n",
    "        count = source_dictionaries[key][\"count\"]\n",
    "        malformed_count = source_dictionaries[key][\"malformed_count\"]\n",
    "        device = source_dictionaries[key][\"device\"]\n",
    "\n",
    "        # If there are only malformed packets, a source is \"malformed-only\"\n",
    "        if (count - malformed_count) == 0:\n",
    "            only_malformed_sources.append(key)\n",
    "        \n",
    "        # Get all sources which are not part of the target group (and contain at least 1 valid packet)\n",
    "        if (count - malformed_count) != 0 and device == \"empty\":\n",
    "            empty_sources.append(key)\n",
    "\n",
    "    print(f\"Only Malformed Sources: {len(only_malformed_sources)}\")\n",
    "    print(f\"Empty Sources: {len(empty_sources)}\")\n",
    "\n",
    "    return only_malformed_sources, empty_sources\n",
    "\n",
    "# Recursively reassign sources due to non-deterministic BLE packet contents\n",
    "# --> Extensively described in the thesis\n",
    "def reassign_sources():\n",
    "    empty_occurrences = 0\n",
    "    new_final_list = []\n",
    "\n",
    "    for row_dict in final_list:\n",
    "        if row_dict[\"labelled_device\"] == \"empty\" and row_dict[\"company_id\"] in phone_companies:\n",
    "            current_source = row_dict[\"source\"]\n",
    "            row_dict[\"labelled_device\"] = source_dictionaries[current_source][\"device\"]\n",
    "\n",
    "        if row_dict[\"labelled_device\"] != \"empty\":\n",
    "            new_final_list.append(row_dict)\n",
    "        else:\n",
    "            new_final_list.append(row_dict)\n",
    "            empty_occurrences += 1\n",
    "\n",
    "    return empty_occurrences, new_final_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0d4afde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final dataframe based on the final_list rows\n",
    "def create_labelled_dataframe(entry_list: list):\n",
    "    new_df = pd.DataFrame(data=entry_list, columns=list((final_list[0].keys())))        \n",
    "    return new_df\n",
    "\n",
    "# Write the dataframe to a file\n",
    "def write_new_dataframe(file_to_write: str, df_to_write: pd.DataFrame):\n",
    "    df_to_write.to_csv(file_to_write, encoding='utf-8', index=False)\n",
    "    print(f\"New CSV written as: {file_to_write}\")\n",
    "\n",
    "# Extract information about the sources of a label\n",
    "def info_extractor(df_input: pd.DataFrame, wanted_label: str):\n",
    "    seen_sources = {}\n",
    "    for row in df_input.itertuples(index=False):\n",
    "        if row.source not in seen_sources.keys() and row.sublabel_device == wanted_label:\n",
    "            seen_sources[row.source] = {}\n",
    "            seen_sources[row.source][\"first\"] = row.time\n",
    "            seen_sources[row.source][\"last\"] = row.time\n",
    "            seen_sources[row.source][\"count\"] = source_dictionaries[row.source][\"count\"]\n",
    "            continue\n",
    "        if row.source in seen_sources.keys() and row.sublabel_device == wanted_label:\n",
    "            if seen_sources[row.source][\"last\"] < row.time:\n",
    "                seen_sources[row.source][\"last\"] = row.time\n",
    "\n",
    "    return seen_sources\n",
    "\n",
    "def assign_majority_label(input_df: pd.DataFrame):\n",
    "    # Compute the majority label per source\n",
    "    majority_labels = input_df.groupby('source')['labelled_device'].agg(lambda x: x.mode()[0])\n",
    "    # Map the majority label back to the dataframe\n",
    "    input_df['labelled_device'] = input_df['source'].map(majority_labels)\n",
    "\n",
    "    return input_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1aa84950",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#        CODE FIELD 0        #\n",
    "##############################\n",
    "\n",
    "# Global variables\n",
    "final_list = []\n",
    "source_dictionaries = {}\n",
    "phone_companies = [\"Samsung Electronics Co. Ltd.\", \"Undefined\", \"Unknown\"]\n",
    "undefined_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4114b931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only Malformed Sources: 117308\n",
      "Empty Sources: 165632\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "#        CODE FIELD 1        #\n",
    "##############################\n",
    "\n",
    "# Setup all lists, dictionaries and the labeled dataframe\n",
    "path_to_file = \"../data/samsung/samsung_uni_group3_2h_raw.csv\" # samsung_isolated_group2_6h_raw, samsung_isolated_group3_6h_raw, samsung_uni_group3_2h_raw\n",
    "raw_dataframe = read_data_to_df(path_to_file) \n",
    "all_sources = raw_dataframe[\"Source\"].unique()\n",
    "target_group_rsp_scrs = raw_dataframe.loc[(raw_dataframe[\"Info\"] == \"SCAN_RSP\") & (\n",
    "                                                (raw_dataframe[\"Device_Name\"] == \"Smart Tag\") | \n",
    "                                                (raw_dataframe[\"Device_Name\"] == \"Buds FE\")), \"Source\"].unique()\n",
    "initialize_source_dictionaries(all_sources)\n",
    "nan_counter, malformed_counter = parse_dataframe(raw_dataframe)\n",
    "malformed_list, empty_list = find_empty_and_malformed_sources()\n",
    "empty_counter, filtered_list = reassign_sources()\n",
    "labelled_dataframe = create_labelled_dataframe(filtered_list)\n",
    "relevant_sources = labelled_dataframe[\"source\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0451d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "FINAL DATAFRAME\n",
      "\n",
      "Length Raw Dataframe: 3632931\n",
      "Length Final Dataframe: 3340540\n",
      "Removed: 261153 (malformed), 31238 (NaN), Diff: 292391\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "#        CODE FIELD 2        #\n",
    "##############################\n",
    "\n",
    "# Each source is filtered according to its average RSSI value and count and re-labeled if needed\n",
    "rssi_limits_per_dataset =  {\"samsung_isolated_group2_6h_raw\": {\"Phone Google\": -49,\n",
    "                                                        \"Phone Scan\": -33,\n",
    "                                                        \"Phone Phone\": -45,\n",
    "                                                        \"Smart Tag\": -39},\n",
    "                            \"samsung_isolated_group3_6h_raw\": {\"Phone Google\": -36,\n",
    "                                                             \"Phone Scan\": -17,\n",
    "                                                             \"Smart Tag\": -24},\n",
    "                            \"samsung_uni_group3_2h_raw\": {\"Phone Google\": -32,\n",
    "                                                        \"Phone Scan\": -18,\n",
    "                                                        \"Phone Phone\": -27,\n",
    "                                                        \"Smart Tag\": -20}\n",
    "                            }\n",
    "\n",
    "rssi_limits = rssi_limits_per_dataset[path_to_file.split(\"/\")[-1].split(\".\")[0]]\n",
    "\n",
    "for label in rssi_limits.keys():\n",
    "    sources = info_extractor(labelled_dataframe, label)\n",
    "    actual_target_group_sources = []\n",
    "    for source in sources.keys():\n",
    "        first = round(sources[source][\"first\"], 3)\n",
    "        last = round(sources[source][\"last\"], 3)\n",
    "        count = sources[source][\"count\"]\n",
    "        max_rssi = source_dictionaries[source][\"highest_rssi\"]\n",
    "        low_rssi = source_dictionaries[source][\"lowest_rssi\"]\n",
    "        avg_rssi = source_dictionaries[source][\"average_rssi\"]\n",
    "\n",
    "        # Find Phone Google labeled sources\n",
    "        if label == \"Phone Google\" and source_dictionaries[source][\"sub_device\"] == label:\n",
    "            if count > 30 and avg_rssi > rssi_limits[\"Phone Google\"]: \n",
    "                actual_target_group_sources.append(source)\n",
    "\n",
    "        # Find Phone Scan labeled sources\n",
    "        if label == \"Phone Scan\" and source_dictionaries[source][\"sub_device\"] == label:\n",
    "            if count > 30 and avg_rssi >= rssi_limits[\"Phone Scan\"]:\n",
    "                actual_target_group_sources.append(source)\n",
    "\n",
    "        if label == \"Phone Phone\" and source_dictionaries[source][\"sub_device\"] == label:\n",
    "            if count > 30 and avg_rssi >= rssi_limits[\"Phone Phone\"]:\n",
    "                actual_target_group_sources.append(source)\n",
    "        \n",
    "        \n",
    "        # Find Smart Tag labeled sources\n",
    "        if label == \"Smart Tag\" and source_dictionaries[source][\"sub_device\"] == label:\n",
    "            if count > 30 and avg_rssi >= rssi_limits[\"Smart Tag\"]:\n",
    "                actual_target_group_sources.append(source)\n",
    "\n",
    "    # Reassign the labels based on the above conditions\n",
    "    current_target_group_sources = labelled_dataframe[labelled_dataframe['sublabel_device'] == label][\"source\"]\n",
    "    diff_sources = set(current_target_group_sources) - set(actual_target_group_sources)\n",
    "    labelled_dataframe.loc[labelled_dataframe['source'].isin(diff_sources), 'labelled_device'] = 'empty'\n",
    "\n",
    "# Print information about dataframe length\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"FINAL DATAFRAME\\n\")\n",
    "print(f\"Length Raw Dataframe: {len(raw_dataframe)}\")\n",
    "print(f\"Length Final Dataframe: {len(labelled_dataframe)}\")\n",
    "print(f\"Removed: {malformed_counter} (malformed), {nan_counter} (NaN), Diff: {len(raw_dataframe)-len(labelled_dataframe)}\")\n",
    "\n",
    "# Assign the majority label to impure sources (for example a phone source may have 3000 \"Phone\" labels and 1 \"empty\" labels) --> apply majority label\n",
    "labelled_dataframe = assign_majority_label(labelled_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "605b7996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  packets  sources\n",
      "labelled_device                  \n",
      "empty            3078478   165907\n",
      "Phone             203347       78\n",
      "Buds               52708        1\n",
      "Smart Tag           6007       17\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "#        CODE FIELD 3        #\n",
    "##############################\n",
    "\n",
    "print(\"\\n\", labelled_dataframe.groupby(\"labelled_device\").agg(packets=(\"labelled_device\", \"size\"), sources=(\"source\", \"nunique\")).sort_values(by=\"packets\", ascending=False))\n",
    "# Check if there are still impure sources which have multiple labels\n",
    "# After assigning the majority label this output should be empty\n",
    "multi_label_sources = labelled_dataframe.groupby('source')['labelled_device'].nunique()\n",
    "multi_label_sources = multi_label_sources[multi_label_sources > 1].index\n",
    "\n",
    "for source in multi_label_sources:\n",
    "    print(\"\\n\", labelled_dataframe[labelled_dataframe[\"source\"] == source][\"labelled_device\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be34f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_src(df):\n",
    "    result = (\n",
    "    df.groupby(\"source\")\n",
    "      .agg(\n",
    "          count=(\"rssi\", \"count\"),\n",
    "          RSSI_min=(\"rssi\", \"min\"),\n",
    "          RSSI_max=(\"rssi\", \"max\"),\n",
    "          RSSI_avg=(\"rssi\", \"mean\"),\n",
    "          length_counts=(\"length\", lambda x: x.value_counts().to_dict()),\n",
    "          label=(\"labelled_device\", lambda x: x.unique())\n",
    "      )\n",
    "      .reset_index()                \n",
    "      .sort_values(by=\"count\", ascending=False)\n",
    "      .reset_index(drop=True)\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa52e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#        CODE FIELD 4        #\n",
    "##############################\n",
    "\n",
    "# remove noise entries from isolated dataset\n",
    "if path_to_file.split(\"/\")[-1].split(\".\")[0].split(\"_\")[1] == \"isolated\":\n",
    "    print(group_by_src(labelled_dataframe[labelled_dataframe[\"labelled_device\"] == \"empty\"]).to_string())\n",
    "    # remove rows with empty device label\n",
    "    to_drop = (labelled_dataframe[\"labelled_device\"] == \"empty\")\n",
    "    labelled_dataframe = labelled_dataframe.drop(labelled_dataframe[to_drop].index)\n",
    "    print(f\"Number of entries with label 'empty': {len(labelled_dataframe[labelled_dataframe[\"labelled_device\"] == \"empty\"])}\")\n",
    "\n",
    "# save labelled dataframe as csv\n",
    "new_file_name = \"_\".join(path_to_file.split(\"/\")[-1].split(\".\")[0].split(\"_\")[:-1])\n",
    "labelled_dataframe.to_csv(f\"D../data/samsung/{new_file_name}_labeled.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
